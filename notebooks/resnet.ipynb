{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import train, predict\n",
    "from dataset import train_cats_dogs, test_cats_dogs\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape: torch.Size([3, 224, 224])\n",
      "torch.Size([1, 128, 56, 56])\n",
      "Prediction: None\n"
     ]
    }
   ],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.conv1_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, padding='same'),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv2_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=7, padding='same'),\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv64_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding='same'),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding='same'),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv128_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding='same'),\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.classification_head = nn.Sequential(\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.unsqueeze(dim=0)\n",
    "        output_conv1 = self.conv1_block(x)\n",
    "        output_conv2 = self.conv64_block(output_conv1)\n",
    "        input_conv3 = F.relu(output_conv1 + output_conv2)\n",
    "        output_conv4 = self.conv64_block(input_conv3)\n",
    "        input_conv5 = F.relu(input_conv3 + output_conv4)\n",
    "        output_conv5 = self.conv64_block(input_conv5)\n",
    "        input_conv6 = F.relu(output_conv5 + input_conv5)\n",
    "        output_conv7 = self.conv2_block(input_conv6)\n",
    "        output_conv8 = self.conv128_block(output_conv7)\n",
    "        output_conv9 = self.conv128_block(self.conv128_block(output_conv8))\n",
    "        input_conv10 = F.relu(output_conv9 + output_conv8)\n",
    "        print(input_conv10.shape)\n",
    "\n",
    "\n",
    "image, labels = next(iter(test_cats_dogs))\n",
    "model = ResNet()\n",
    "print(f\"Image Shape: {image.shape}\")\n",
    "print(f\"Prediction: {predict(model, image)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape               Output Shape              Param #                   Trainable\n",
       "============================================================================================================================================\n",
       "ResNet (ResNet)                          [3, 224, 224]             --                        --                        --\n",
       "============================================================================================================================================\n",
       "Total params: 0\n",
       "Trainable params: 0\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0\n",
       "============================================================================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.60\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model, input_size=(3, 224, 224), col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"], row_settings=[\"var_names\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
